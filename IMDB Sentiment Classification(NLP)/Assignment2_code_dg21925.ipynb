{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e27b961",
   "metadata": {},
   "source": [
    "# Importing the dependancies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "813346c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.metrics import *\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55180b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the data into a Pandas dataframe\n",
    "df = pd.read_csv(\"IMDB Dataset.csv\",low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07aa2214",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Changing the sentiment part in the data to boolean\n",
    "df[\"sentiment\"].replace({\"positive\": 1, \"negative\": 0}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "edf6c050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  review  sentiment\n",
      "0      One of the other reviewers has mentioned that ...          1\n",
      "1      A wonderful little production. <br /><br />The...          1\n",
      "2      I thought this was a wonderful way to spend ti...          1\n",
      "3      Basically there's a family where a little boy ...          0\n",
      "4      Petter Mattei's \"Love in the Time of Money\" is...          1\n",
      "...                                                  ...        ...\n",
      "49995  I thought this movie did a down right good job...          1\n",
      "49996  Bad plot, bad dialogue, bad acting, idiotic di...          0\n",
      "49997  I am a Catholic taught in parochial elementary...          0\n",
      "49998  I'm going to have to disagree with the previou...          0\n",
      "49999  No one expects the Star Trek movies to be high...          0\n",
      "\n",
      "[50000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548481fd",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eba57843",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\david\\miniconda3\\envs\\ce802\\lib\\site-packages\\ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "#For lemmatizing or stemming\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "stemmer = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "#Getting the english stopwords\n",
    "stopwords = stopwords.words('english')\n",
    "\n",
    "#For each review removes the non alphanumeric characters and stopwords and converts to lower case\n",
    "#To use stemming or lemmatizing please uncomment the corresponding part\n",
    "for i in range(len(df[\"review\"])):\n",
    "    row=df[\"review\"][i]\n",
    "    my_list = row.split(\" \")\n",
    "    words = []\n",
    "    for w in my_list:\n",
    "         if (w.isalnum()) and w not in stopwords:\n",
    "            w=w.lower()\n",
    "            #w=stemmer.stem(w)\n",
    "            #w=lemmatizer.lemmatize(w)\n",
    "            words.append(w)\n",
    "    my_string = ' '.join(words)\n",
    "    #print(my_string)\n",
    "    df[\"review\"][i]=my_string\n",
    "            \n",
    " \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386637e2",
   "metadata": {},
   "source": [
    "# Analyzing the linguistic features in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09d9cdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Takes the words in the positive and negative reviews separately\n",
    "pos=[]\n",
    "neg=[]\n",
    "for i in range(len(df[\"sentiment\"])):\n",
    "    list=df['review'][i].split(\" \")\n",
    "    if(df['sentiment'][i]==1):\n",
    "        for el in list:\n",
    "            pos.append(el)\n",
    "    else:\n",
    "        for el in list:\n",
    "            neg.append(el)\n",
    "#Converts the list to pandas dataframe\n",
    "df_pos=pd.DataFrame(pos)\n",
    "df_neg=pd.DataFrame(neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d89ec921",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculates the frequency distributions\n",
    "posfreq = nltk.FreqDist(df_pos[0])\n",
    "negfreq = nltk.FreqDist(df_neg[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a6ddbef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 5 most common words in positive reviews:\n",
      "\n",
      "'i' occurred 62219 times\n",
      "'the' occurred 34324 times\n",
      "'film' occurred 29361 times\n",
      "'movie' occurred 26678 times\n",
      "'one' occurred 23268 times\n",
      "\n",
      "The 5 most common words in negative reviews:\n",
      "\n",
      "'i' occurred 70269 times\n",
      "'the' occurred 35774 times\n",
      "'movie' occurred 34805 times\n",
      "'film' occurred 25717 times\n",
      "'one' occurred 21710 times\n"
     ]
    }
   ],
   "source": [
    "#Printing the 5 most common words in both positive and negative reviews\n",
    "pos_most_common_list=posfreq.most_common(5)\n",
    "neg_most_common_list=negfreq.most_common(5)\n",
    "print (\"The 5 most common words in positive reviews:\\n\")\n",
    "for i,j in pos_most_common_list:\n",
    "    print(\"'\"+str(i)+\"' occurred \"+str(j)+\" times\")\n",
    "print (\"\\nThe 5 most common words in negative reviews:\\n\")\n",
    "for i,j in neg_most_common_list:\n",
    "    print(\"'\"+str(i)+\"' occurred \"+str(j)+\" times\")\n",
    "#As you can see the most common words are common in both positive and negative reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4565be23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of occurances of the word 'great'in positive reviews are 11139\n",
      "The number of occurances of the word 'great'in negative reviews are 4326\n",
      "The number of occurances of the word 'worst'in positive reviews are 371\n",
      "The number of occurances of the word 'worst'in negative reviews are 4411\n"
     ]
    }
   ],
   "source": [
    "#Checking the frequency of certain words in positive and negative reviews\n",
    "print(\"The number of occurances of the word 'great'in positive reviews are \"+str(df_pos[0].value_counts()['great']))\n",
    "print(\"The number of occurances of the word 'great'in negative reviews are \"+str(df_neg[0].value_counts()['great']))\n",
    "print(\"The number of occurances of the word 'worst'in positive reviews are \"+str(df_pos[0].value_counts()['worst']))\n",
    "print(\"The number of occurances of the word 'worst'in negative reviews are \"+str(df_neg[0].value_counts()['worst']))\n",
    "#As you can see some words occur more in positive reviews and some others occur more in negative reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6251374b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The avg length of positive review is 100.10028 words\n",
      "The avg length of negative review is 98.01312 words\n"
     ]
    }
   ],
   "source": [
    "#Calculating the avg number of words in positive and negative reviews and comparing both\n",
    "poslensum=0\n",
    "posnum=0\n",
    "neglensum=0\n",
    "negnum=0\n",
    "for i in range(len(df[\"sentiment\"])):\n",
    "    list=df['review'][i].split(\" \")\n",
    "    if(df['sentiment'][i]==1):\n",
    "        poslensum+=len(list)\n",
    "        posnum+=1\n",
    "    else:\n",
    "        neglensum+=len(list)\n",
    "        negnum+=1\n",
    "        \n",
    "print(\"The avg length of positive review is \"+str(poslensum/posnum)+\" words\")\n",
    "print(\"The avg length of negative review is \"+str(neglensum/negnum)+\" words\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f73428",
   "metadata": {},
   "source": [
    "# Dividing the data into training data and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "59511efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#40000 is for training and rest 10000 is for testing\n",
    "df_train = df.iloc[:40000,:]\n",
    "df_test = df.iloc[40001:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9dfe52f",
   "metadata": {},
   "source": [
    "# 1.Using Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "012eed3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting the data to vector format to feed into the model\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vector = TfidfVectorizer(min_df = 5,\n",
    "                             max_df = 0.8,\n",
    "                             sublinear_tf = True,\n",
    "                             use_idf = True)\n",
    "svm_train = vector.fit_transform(df_train['review'])\n",
    "svm_test = vector.transform(df_test['review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0acfc01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#Defining the classifier\n",
    "classifier = svm.SVC(kernel='linear')\n",
    "\n",
    "#Training\n",
    "classifier.fit(svm_train, df_train['sentiment'])\n",
    "\n",
    "#Prediction\n",
    "prediction = classifier.predict(svm_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8eee3ac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive:  {'precision': 0.8746280499900814, 'recall': 0.8805672059117235, 'f1-score': 0.8775875796178344, 'support': 5007}\n",
      "negative:  {'precision': 0.8793868495361032, 'recall': 0.8733974358974359, 'f1-score': 0.8763819095477386, 'support': 4992}\n"
     ]
    }
   ],
   "source": [
    "#Generating report with precision, recall,etc.\n",
    "report = classification_report(df_test['sentiment'], prediction, output_dict=True)\n",
    "print('positive: ', report['1'])\n",
    "print('negative: ', report['0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "90ee889f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.876987698769877"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculating the accuracy\n",
    "accuracy_score(df_test['sentiment'], prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1562397f",
   "metadata": {},
   "source": [
    "# 2.Using XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9aa7310a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4e90cb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting the data to vector format to feed into the model\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vector1 = CountVectorizer(binary = True) \n",
    "vector1.fit(df['review']) # find all the unique words from the training set\n",
    "train_x = vector1.fit_transform(df_train['review'])\n",
    "test_x = vector1.transform(df_test['review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2ca40a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting the data to the required format to feed into the xgb model\n",
    "xgb_train = xgb.DMatrix(train_x, df_train['sentiment'])\n",
    "xgb_test = xgb.DMatrix(test_x, df_test['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "30bc8ce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:13:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"n_thread\", \"scale_pos_weight\", \"verbose\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Defining the parameters for the model\n",
    "param = {        \n",
    "        'objective':'multi:softprob',\n",
    "        'learning_rate':0.75,\n",
    "        'max_depth':50,\n",
    "        'num_class':2,\n",
    "        'subsample':0.8,\n",
    "        'colsample_bytree':0.8,\n",
    "        'eval_metric':'mlogloss',\n",
    "        'min_child_weight':10,\n",
    "        'reg_alpha':1.5, \n",
    "        'reg_lambda':5,\n",
    "        'scale_pos_weight':1,  \n",
    "        'verbose':1,        \n",
    "        'n_thread':-1 \n",
    "    }\n",
    "\n",
    "#Training the model\n",
    "xgb_model =xgb.train(param,xgb_train,num_boost_round = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2ed7481e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prediction\n",
    "prediction1 = xgb_model.predict(xgb_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6d4cb966",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding the appropriate class between 0 and 1 based on which has higher score\n",
    "prediction1 = np.asarray([np.argmax(line) for line in prediction1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "46d26ce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive:  {'precision': 0.8444755804643715, 'recall': 0.8426203315358498, 'f1-score': 0.8435469359192243, 'support': 5007}\n",
      "negative:  {'precision': 0.8424945032980212, 'recall': 0.8443509615384616, 'f1-score': 0.8434217108554277, 'support': 4992}\n"
     ]
    }
   ],
   "source": [
    "#Generating report with precision, recall,etc.\n",
    "report1 = classification_report(df_test['sentiment'], prediction1, output_dict=True)\n",
    "print('positive: ', report1['1'])\n",
    "print('negative: ', report1['0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "051db8be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8434843484348434"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculating the accuracy\n",
    "accuracy_score(df_test['sentiment'], prediction1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb15d1f",
   "metadata": {},
   "source": [
    "# References "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b62554",
   "metadata": {},
   "source": [
    "https://www.geeksforgeeks.org/python-stemming-words-with-nltk/\n",
    "https://www.geeksforgeeks.org/python-lemmatization-with-nltk/\n",
    "https://medium.com/@vasista/sentiment-analysis-using-svm-338d418e3ff1\n",
    "https://ai.plainenglish.io/sentiment-classification-using-xgboost-7abdaf4771f9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67bb2b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
